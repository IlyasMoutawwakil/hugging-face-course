{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "In Chapter 3, we looked at how to fine-tune a model on a given task. When we do that, we use the same tokenizer that the model was pretrained with ‚Äî but what do we do when we want to train a model from scratch? In these cases, using a tokenizer that was pretrained on a corpus from another domain or language is typically suboptimal. For example, a tokenizer that‚Äôs trained on an English corpus will perform poorly on a corpus of Japanese texts because the use of spaces and punctuation is very different in the two languages.\n",
    "\n",
    "In this chapter, you will learn how to train a brand new tokenizer on a corpus of texts, so it can then be used to pretrain a language model. This will all be done with the help of the [ü§ó Tokenizers](https://github.com/huggingface/tokenizers) library, which provides the ‚Äúfast‚Äù tokenizers in the [ü§ó Transformers](https://github.com/huggingface/transformers) library. We‚Äôll take a close look at the features that this library provides, and explore how the fast tokenizers differ from the ‚Äúslow‚Äù versions.\n",
    "\n",
    "Topics we will cover include:\n",
    "- How to train a new tokenizer similar to the one used by a given checkpoint on a new corpus of texts\n",
    "- The special features of fast tokenizers\n",
    "- The differences between the three main subword tokenization algorithms used in NLP today\n",
    "- How to build a tokenizer from scratch with the ü§ó Tokenizers library and train it on some data\n",
    "\n",
    "The techniques introduced in this chapter will prepare you for the section in Chapter 7 where we look at creating a language model for Python source code. Let‚Äôs start by looking at what it means to ‚Äútrain‚Äù a tokenizer in the first place."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "483abfc7fdcd927bfa336910f494643cce94b3dfa36bcded073270b8df64edb3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
